{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379a66c",
   "metadata": {},
   "source": [
    "# Action Designator\n",
    "This example will show the different kinds of Action Designator that are available. We will see how to create Action Designators and what they do.\n",
    "\n",
    "\n",
    "Action Designator are high-level descriptions of actions which the robot should execute. \n",
    "\n",
    "Action Deisgnators are created from a Action Designator Descritpion, which describes the type of action as well as the parameter for this action. Parameter are given as a list of possible parameters.\n",
    "For example, if you want to describe the robot moving to a table you would need a ```NavigateAction``` and a list of poses that are near the table. The Action Designator Description will then pick one of the poses and return a performable Action Designator which contains the picked pose. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59363b",
   "metadata": {},
   "source": [
    "## Navigate Action\n",
    "We will start with a simple example of the ```NavigateAction```. \n",
    "\n",
    "First, we need a BulletWorld with a robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ed2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='base_laser_link']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='wide_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='narrow_stereo_optical_frame']\n",
      "Unknown attribute \"type\" in /robot[@name='pr2']/link[@name='laser_tilt_link']\n"
     ]
    }
   ],
   "source": [
    "from pycram.bullet_world import BulletWorld, Object\n",
    "\n",
    "world = BulletWorld()\n",
    "pr2 = Object(\"pr2\", \"pr2\", \"pr2.urdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec859ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e570f78",
   "metadata": {},
   "source": [
    "To move the robot we need to create a description and resolve it to an actual Designator. The description of navigation only needs a list of possible poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0162088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import NavigateAction\n",
    "\n",
    "pose = [[1, 0, 0], [0, 0, 0, 1]]\n",
    "\n",
    "# This is the Designator Description\n",
    "navigate_description = NavigateAction(target_locations=[pose])\n",
    "\n",
    "# This is the performable Designator\n",
    "navigate_designator = navigate_description.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695f899",
   "metadata": {},
   "source": [
    "What we now did was create the pose were we want to move the robot, create a description describing a navigation with a list of possible poses (in this case the list contains only one pose) and create an action designator from the description. The action designator contains the pose picked from the list of possible poses and can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39a4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    navigate_designator.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa7ed5",
   "metadata": {},
   "source": [
    "Every designator that is performed needs to be in an environment that specifies where to perform the designator either on the real robot or the simulated one. This environment is called ```simulated_robot``` similar there is also a ```real_robot``` environment. \n",
    "\n",
    "There are also decorators which do the same thing but for whole methods, they are called ```with_real_robot``` and ```with_simulated_robor```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b708d18",
   "metadata": {},
   "source": [
    "## Move Torso\n",
    "This action designator moves the torso up or down, specifically it sets the torso joint to a given value.\n",
    "\n",
    "We start again by creating a description and resolving it to a designator. Afterwards, the designator is perfomed in a ```simulated_robot``` environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf76f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import MoveTorsoAction\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "torso_pose = 0.2\n",
    "\n",
    "torso_desig = MoveTorsoAction([torso_pose]).resolve()\n",
    "\n",
    "with simulated_robot:\n",
    "    torso_desig.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa090e9",
   "metadata": {},
   "source": [
    "## Set Gripper\n",
    "As the name implies, this action designator is used to open or close the gripper. \n",
    "\n",
    "The procedure is similar to the last time, but this time we will shorten it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e8af484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import SetGripperAction\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "gripper = \"right\"\n",
    "motion = \"open\"\n",
    "\n",
    "with simulated_robot:\n",
    "    SetGripperAction(grippers=[gripper], motions=[motion]).resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f130e09d",
   "metadata": {},
   "source": [
    "## Park Arms\n",
    "Park arms is used to move one or both arms into the default parking position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9bd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import ParkArmsAction\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.enums import Arms\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4353e",
   "metadata": {},
   "source": [
    "## Pick Up and Place\n",
    "Since these are depending on each other, meaning you can only place something when you picked it up beforehand, they will be shown together. \n",
    "\n",
    "These action designators use object designators, which will not be further explained so please check the example on object designators for more details. \n",
    "\n",
    "To start we need an environment in which we can pick up and place things as well as an object to pick up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff2c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchen = Object(\"kitchen\", \"environment\", \"kitchen.urdf\")\n",
    "milk = Object(\"milk\", \"milk\", \"milk.stl\", position=[1.3, 1, 0.9])\n",
    "\n",
    "world.reset_bullet_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f953d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import PickUpAction, PlaceAction, ParkArmsAction, MoveTorsoAction, NavigateAction\n",
    "from pycram.designators.object_designator import BelieveObject\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.enums import Arms\n",
    "\n",
    "milk_desig = BelieveObject(names=[\"milk\"])\n",
    "arm =\"right\"\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    \n",
    "    MoveTorsoAction([0.3]).resolve().perform()\n",
    "    \n",
    "    NavigateAction([[[0.72, 0.98, 0.0], \n",
    "                     [0.0, 0.0, 0.014701099828940344, 0.9998919329926708]]]).resolve().perform()\n",
    "    \n",
    "    PickUpAction(object_designator_description=milk_desig, \n",
    "                     arms=[arm], \n",
    "                     grasps=[\"right\"]).resolve().perform()\n",
    "    \n",
    "    NavigateAction([[[-1.90, 0.78, 0.0], \n",
    "                     [0.0, 0.0, 0.16439898301071468, 0.9863939245479175]]]).resolve().perform()\n",
    "    \n",
    "    PlaceAction(object_designator_description=milk_desig, \n",
    "                target_locations=[[[-1.20, 1.0192, 0.9624], \n",
    "                                   [0.0, 0.0, 0.6339889056055381, 0.7733421413379024]]], \n",
    "                arms=[arm]).resolve().perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d50ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.reset_bullet_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108b7957",
   "metadata": {},
   "source": [
    "## Look At\n",
    "Look at lets the robot look at a specific point, for example if it should look at an object for detecting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "279f715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.action_designator import LookAtAction\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "target_location = [[1, 0, 0.5], [0, 0, 0, 1]]\n",
    "with simulated_robot:\n",
    "    LookAtAction(targets=[target_location]).resolve().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36358cc",
   "metadata": {},
   "source": [
    "# Detect\n",
    "Detect is used to detect objects in the field of vision (FOV) of the robot. We will use the milk used in the pick up/place example, if you didn't execute that example you can spawn the milk with the following cell. The detect designator will return a resolved instance of an ObjectDesignatorDescription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c192718",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk = Object(\"milk\", \"milk\", \"milk.stl\", position=[1.3, 1, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "145af79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1.3, 1.0, 0.9), (0.0, 0.0, 0.0, 1.0))\n"
     ]
    },
    {
     "ename": "PerceptionObjectNotFound",
     "evalue": "Could not find an object with the type milk in the FOV of the robot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPerceptionObjectNotFound\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5549cc38a027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mLookAtAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmilk_desig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mobj_desig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetectAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmilk_desig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/ros/src/pycram-1/src/pycram/task.py\u001b[0m in \u001b[0;36mhandle_tree\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mtask_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mtask_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaskStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# set and time and update current node pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ros/src/pycram-1/src/pycram/task.py\u001b[0m in \u001b[0;36mhandle_tree\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mtask_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaskStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCREATED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mtask_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;31m# if it succeeded set the flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ros/src/pycram-1/src/pycram/task.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAnything\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0massociated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mwill\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# def __str__(self) -> str:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ros/src/pycram-1/src/pycram/designators/action_designator.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwith_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDetectingMotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_designator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/ros/src/pycram-1/src/pycram/designators/motion_designator.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mbullet_world_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbullet_world_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 raise PerceptionObjectNotFound(\n\u001b[0m\u001b[1;32m    263\u001b[0m                     f\"Could not find an object with the type {self.object_type} in the FOV of the robot\")\n\u001b[1;32m    264\u001b[0m             return ObjectDesignatorDescription.Object(bullet_world_object.name, bullet_world_object.type,\n",
      "\u001b[0;31mPerceptionObjectNotFound\u001b[0m: Could not find an object with the type milk in the FOV of the robot"
     ]
    }
   ],
   "source": [
    "from pycram.designators.action_designator import DetectAction, LookAtAction, ParkArmsAction\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "milk_desig = BelieveObject(names=[\"milk\"])\n",
    "print(milk_desig.resolve().pose)\n",
    "\n",
    "with simulated_robot:\n",
    "    ParkArmsAction([Arms.BOTH]).resolve().perform()\n",
    "    \n",
    "    NavigateAction([[[0, 1, 0], [0, 0, 0, 1]]]).resolve().perform()\n",
    "    \n",
    "    LookAtAction(targets=[milk_desig.resolve().pose]).resolve().perform()\n",
    "    \n",
    "    obj_desig = DetectAction(milk_desig).resolve().perform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

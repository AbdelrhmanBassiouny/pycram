{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263caf6d",
   "metadata": {},
   "source": [
    "# Motion Designator\n",
    "Motion designators are similar to action designators, but unlike action designators, motion designators represent atomic low-level motions. Motion designators only take the parameter that they should execute and not a list of possible parameters, like the other designators. Like action designators, motion designators can be performed, performing motion designator verifies the parameter and passes the designator to the respective process module. \n",
    "\n",
    "Since motion designators perform a motion on the robot, we need a robot which we can use. Therefore, we will create a BulletWorld as well as a PR2 robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90636d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.worlds.bullet_world import BulletWorld\n",
    "from pycram.world_concepts.world_object import Object\n",
    "from pycram.datastructures.enums import ObjectType, WorldMode\n",
    "\n",
    "world = BulletWorld(WorldMode.GUI)\n",
    "pr2 = Object(\"pr2\", ObjectType.ROBOT, \"pr2.urdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa15c7e",
   "metadata": {},
   "source": [
    "## Move\n",
    "Move is used to let the robot drive to the given target pose. Motion designator are used in the same way as the other designator, first create a description then resolve it to the actual designator and lastly, perform the resolved designator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa3bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.datastructures.pose import Pose\n",
    "from pycram.designators.motion_designator import MoveMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveMotion(target=Pose([1, 0, 0], [0, 0, 0, 1]))\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98420444",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.reset_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5c9d7",
   "metadata": {},
   "source": [
    "## MoveTCP\n",
    "MoveTCP is used to move the tool center point (TCP) of the given arm to the target position specified by the parameter. Like any designator we start by creating a description and then resolving and performing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3740d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveTCPMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.datastructures.enums import Arms\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveTCPMotion(target=Pose([0.5, 0.6, 0.6], [0, 0, 0, 1]), arm=Arms.LEFT)\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d529aa",
   "metadata": {},
   "source": [
    "## Looking\n",
    "Looking motion designator adjusts the robot state such that the cameras point towards the target pose. Although this motion designator takes the target as position and orientation, in reality only the position is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import LookingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = LookingMotion(target=Pose([1, 1, 1], [0, 0, 0, 1]))\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06216beb",
   "metadata": {},
   "source": [
    "## Move Gripper\n",
    "Move gripper moves the gripper of an arm to one of two states. The states can be ```open``` and ```close```, which open and close the gripper respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveGripperMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "from pycram.datastructures.enums import Arms, GripperState\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveGripperMotion(motion=GripperState.OPEN, gripper=Arms.LEFT)\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07723340",
   "metadata": {},
   "source": [
    "## Detecting \n",
    "This is the motion designator implementation of detecting, if an object with the given object type is in the field of view (FOV) this motion designator will return an object designator describing the object.\n",
    "\n",
    "Since we need an object that we can detect, we will spawn a milk for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([1.5, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672770e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import DetectingMotion, LookingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    LookingMotion(target=Pose([1.5, 0, 1], [0, 0, 0, 1])).perform()\n",
    "    \n",
    "    motion_description = DetectingMotion(object_type=ObjectType.MILK)\n",
    "    \n",
    "    obj = motion_description.perform()\n",
    "    \n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13747799",
   "metadata": {},
   "source": [
    "## Move Arm Joints\n",
    "This motion designator moves one or both arms. Movement targets are a dictionary with joint name as key and target pose as value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354aca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveArmJointsMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveArmJointsMotion(right_arm_poses={\"r_shoulder_pan_joint\": -0.7})\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32e6c37",
   "metadata": {},
   "source": [
    "## World State Detecting\n",
    "World state detecting is also used to detect objects, however, the object is not required to be in the FOV of the robot. As long as the object is somewhere in the belief state (BulletWorld) a resolved object designator will be returned.\n",
    "\n",
    "Sine we want to detect something we will spawn an object that we can detect. If you already spawned the milk from the previous example, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "milk = Object(\"milk\", ObjectType.MILK, \"milk.stl\", pose=Pose([-1, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa70fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import WorldStateDetectingMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = WorldStateDetectingMotion(object_type=ObjectType.MILK)\n",
    "    \n",
    "    obj = motion_description.perform()\n",
    "    \n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815c1a9",
   "metadata": {},
   "source": [
    "## Move Joints\n",
    "Move joints can move any number of joints of the robot, the designator takes two lists as parameter. The first list are the names of all joints that should be moved and the second list are the positions to which the joints should be moved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04764188",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from pycram.designators.motion_designator import MoveJointsMotion\n",
    "from pycram.process_module import simulated_robot\n",
    "\n",
    "with simulated_robot:\n",
    "    motion_description = MoveJointsMotion(names=[\"torso_lift_joint\", \"r_shoulder_pan_joint\"], positions=[0.2, -1.2])\n",
    "    \n",
    "    motion_description.perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e552caa",
   "metadata": {},
   "source": [
    "The following cell can be used after testing the examples, to close the BulletWorld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "world.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
